<!DOCTYPE html>
<html lang="ja">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="description" content="1. どんなもの？ 物体検出によるbottom-up attentionと重み付き平均を用いたtop-down attentionの両方を組み合わせることにより，Image CaptioningとVisual Question Answeringの両方のタスクにおいてSOTAを達成． 2. 先行研究と比べてどこがすごいの？ 従来のImage captioningやVideo...">
        <meta name="keywords" content="CVPR2018, IDG, VQA">
        <link rel="icon" href="https://matasuke.github.io/papers/favicon.ico">

        <title>Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering - Paper Survey</title>

        <!-- Stylesheets -->
        <link href="https://matasuke.github.io/papers/theme/css/all.min.css" rel="stylesheet">
        <!-- /Stylesheets -->

        <!-- RSS Feeds -->
        <link href="https://matasuke.github.io/papers/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Paper Survey Full Atom Feed" />
        <link href="https://matasuke.github.io/papers/feeds/cv.atom.xml" type="application/atom+xml" rel="alternate" title="Paper Survey Categories Atom Feed" />
        <!-- /RSS Feeds -->

        <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
        <!--[if lt IE 9]>
          <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
          <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
        <![endif]-->



    </head>

    <body>

        <!-- Header -->
    <div class="header-container gradient">

            <!-- Static navbar -->
            <div class="container">
                <div class="header-nav">
                    <div class="header-logo">
                        <!--<a class="pull-left" href="https://matasuke.github.io/papers/"><img class="mr20" src="https://matasuke.github.io/papersimages/site_images/s_logo.png" alt="logo">Paper Survey</a> -->
                        <a class="pull-left" href="https://matasuke.github.io/papers/">Paper Survey</a>
                    </div>
                    <div class="nav pull-right">
                                <a href="https://matasuke.github.io/papers/paper-survey.html">About</a>
                                <a href="https://matasuke.github.io/papers/category/cv.html">CV</a>
                                <a href="https://matasuke.github.io/papers/category/nlp.html">NLP</a>
                                <a href="https://matasuke.github.io/papers/category/ml.html">ML</a>
                    </div>
                </div>
            </div>
            <!-- /Static navbar -->

            <!-- Header -->
    <!-- Header -->
    <div class="container header-wrapper">
        <div class="row">
              <div class="col-lg-12">
                  <div class="header-content">
                      <h1 class="header-title">Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering</h1>
                      <p class="header-date">By <a href="https://matasuke.github.io/papers/author/kosuke-futamata.html">Kosuke Futamata</a>, Mon 23 July 2018, in category <a href="https://matasuke.github.io/papers/category/cv.html">Cv</a></p>
                      <div class="header-underline"></div>
                      <div class="clearfix"></div>
                      <p class="pull-right header-tags">
                          <span class="glyphicon glyphicon-tags mr5" aria-hidden="true"></span>
<a href="https://matasuke.github.io/papers/tag/cvpr2018.html">CVPR2018</a>, <a href="https://matasuke.github.io/papers/tag/idg.html">IDG</a>, <a href="https://matasuke.github.io/papers/tag/vqa.html">VQA</a>                      </p>
                  </div>
              </div>
        </div>
    </div>
    <!-- /Header -->
            <!-- /Header -->

        </div>
        <!-- /Header -->


        <!-- Content -->
    <div class="container content">
        <h2>1. どんなもの？</h2>
<p>物体検出によるbottom-up attentionと重み付き平均を用いたtop-down attentionの両方を組み合わせることにより，Image CaptioningとVisual Question Answeringの両方のタスクにおいてSOTAを達成．</p>
<p><img alt="image1" src="https://matasuke.github.io/papers/images/cv/bottom-up_and_top-down/figure1.png"></p>
<h2>2. 先行研究と比べてどこがすごいの？</h2>
<p>従来のImage captioningやVideo Question Answeringのタスクではほとんどの場合，逐次生成されるキャプションの結果や質問と画像のpixel wise feature vectorによる重み付き平均によるtop-down型のvisual attentionを用いる．
一方で本研究では，画像のpixel wise feature vectoreではなく，Faster R-CNNなどの物体検出アルゴリズムを用いたbottom-up attentionの出力結果に対してtop-down attentionを適用している．</p>
<h2>3. 技術や手法の"キモ"はどこにある？</h2>
<p>bottom-up attentionの出力結果をtop-down attentionに適用している．
物体検出アルゴリズムとして知られるFaster R-CNNの出力結果である部分画像に対してmean-pooled convolutionを適用したfeature vectoresに対してattentionを貼る．
さらに，これらfeature vectoresの平均を取ったのをNetworkの入力として用いる．</p>
<p><img alt="image2" src="https://matasuke.github.io/papers/images/cv/bottom-up_and_top-down/figure2.png"></p>
<p>bottom-up attentionを用いる以外はImage Captioning及びVisual Question AnsweringのNetworksに変わった構造は見られない．</p>
<p><img alt="image2" src="https://matasuke.github.io/papers/images/cv/bottom-up_and_top-down/figure3.png"></p>
<p><img alt="image2" src="https://matasuke.github.io/papers/images/cv/bottom-up_and_top-down/figure4.png"></p>
<h2>4. どうやって有効だと検証した？</h2>
<h3>データセット</h3>
<ul>
<li>Visual Genome</li>
<li>MSCOCO</li>
<li>VQA v2.0</li>
</ul>
<h3>比較対象</h3>
<h3>Image Captioning</h3>
<ul>
<li>SCST(SOTAだったモデル)</li>
<li>ResNet(提案手法のbottom-up attentionをResNetに置換)</li>
<li>up-down(bottom-up and top-down approach)</li>
</ul>
<p>ResNetはvisual attentionにResNet101を用いて，最終層のconv layerの出力を10*10にリサイズ．
通常のvisual attentionと同様に，pixel-wiseのfeature vectorに対してattentionを貼る．</p>
<h3>評価</h3>
<ul>
<li>BLEU, METEOR, ROUGE-L, CIEDErは高いほど良い，</li>
<li>SPICEは小さいほど良い．</li>
</ul>
<p><img alt="image5" src="https://matasuke.github.io/papers/images/cv/bottom-up_and_top-down/figure5.png"></p>
<p><img alt="image6" src="https://matasuke.github.io/papers/images/cv/bottom-up_and_top-down/figure6.png"></p>
<p>Image Captioningのタスクでは全ての評価指標において，現SOTAのモデルを上回った．
VQAのタスクでは，2017 VQA challengeに投稿された全てのモデルを上回る正解率であった．</p>
<h2>5. 議論はあるか？</h2>
<p><img alt="image5" src="https://matasuke.github.io/papers/images/cv/bottom-up_and_top-down/figure7.png"></p>
<p><img alt="image5" src="https://matasuke.github.io/papers/images/cv/bottom-up_and_top-down/figure8.png"></p>
<h2>6. 次に読むべき論文はあるか？</h2>
<ul>
<li><a href="https://arxiv.org/pdf/1708.02711.pdf">'Damien Teney, Peter Anderson, Xiaodong He, Anton van den Hengel', "Tips and Tricks for Visual Question Answering: Learnings from the 2017 Challenge",'2017 VQA Challenge'</a></li>
<li><a href="https://arxiv.org/pdf/1506.01497.pdf">'S. Ren, K. He, R. Girshick, and J. Sun', 'Faster R-CNN: Towards real-time object detection with region proposal networks', 'NIPS 2015'</a></li>
<li><a href="https://arxiv.org/pdf/1704.03162.pdf">'V. Kazemi and A. Elqursh', 'Show, ask, attend, and answer: A
strong baseline for visual question answering.'</a></li>
</ul>
<h3>論文情報・リンク</h3>
<ul>
<li><a href="http://www.panderson.me/images/1707.07998-up-down.pdf">"Peter Anderson, Xiaodong He, Chris Buehler, Damien Teney, Mark Johnson, Stephen Gould, Lei Zhang"，"Bottom-Up and Top-Down Attention for Image Captioning
and Visual Question Answering"，"CVPR 2018"，2018</a></li>
</ul>

            <h4>Articles connexes</h4>
            <dl class="dl-horizontal">
                <dt>Thu 26 July 2018</dt>
                <dd><a href="https://matasuke.github.io/papers/rich-image-captioning-in-the-wild.html">Rich Image Captioning in the Wild</a></dd>
                <dt>Mon 02 July 2018</dt>
                <dd><a href="https://matasuke.github.io/papers/semstyle-learning-to-generate-stylised-image-captions-using-unaligned-text.html">SemStyle: Learning to Generate Stylised Image Captions using Unaligned Text</a></dd>
                <dt>Mon 11 June 2018</dt>
                <dd><a href="https://matasuke.github.io/papers/show-attend-and-tell-neural-image-caption-generation-with-visual-attention.html">Show, Attend and Tell: Neural Image Caption Generation with Visual Attention</a></dd>
                <dt>Thu 02 August 2018</dt>
                <dd><a href="https://matasuke.github.io/papers/stacked-attention-networks-for-image-question-answering.html">Stacked Attention Networks for Image Question Answering</a></dd>
                <dt>Tue 15 May 2018</dt>
                <dd><a href="https://matasuke.github.io/papers/video-question-answering-via-hierarchical-spatio-temporal-attention-networks.html">Video Question Answering via Hierarchical Spatio-Temporal Attention Networks</a></dd>
            </dl>

        
    </div>
        <!-- /Content --> 

        <!-- Footer -->
        <div class="footer gradient-2">
            <div class="container footer-container ">
                <div class="row">
                    <div class="col-xs-4 col-sm-3 col-md-3 col-lg-3">
                        <div class="footer-title">Sitemap</div>
                        <ul class="list-unstyled">
                            <li><a href="https://matasuke.github.io/paperspaper-survey.html">About</a></li>
                            <li><a href="https://matasuke.github.io/papers/categories.html">Categories</a></li>
                            <li><a href="https://matasuke.github.io/papers/tags.html">Tags</a></li>
                            <li><a href="https://matasuke.github.io/papers/feeds/all.atom.xml" type="application/atom+xml" rel="alternate">Atom Feed</a></li>
                        </ul>
                    </div>
                    <div class="col-xs-4 col-sm-3 col-md-3 col-lg-3">
                        <div class="footer-title">Social</div>
                        <ul class="list-unstyled">
                            <li><a href="https://twitter.com/matasuke_f" target="_blank">twitter</a></li>
                            <li><a href="https://github.com/matasuke" target="_blank">github</a></li>
                            <li><a href="https://www.facebook.com/matasukef" target="_blank">facebook</a></li>
                            <li><a href="https://www.linkedin.com/in/kosuke-futamata-862b68124/" target="_blank">linkedin</a></li>
                        </ul>
                    </div>
                    <div class="col-xs-4 col-sm-3 col-md-3 col-lg-3">
                    </div> 
                    <div class="col-xs-12 col-sm-3 col-md-3 col-lg-3">
                        <p class="pull-right text-right">
                            <small><em>Proudly powered by <a href="http://docs.getpelican.com/" target="_blank">pelican</a></em></small><br/>
                            <small><em>Theme and code by <a href="https://github.com/molivier" target="_blank">molivier</a></em></small><br/>
                            <small>&copy; paper survey 2018</small>
                        </p>
                    </div>
                </div>
            </div>
        </div>
        <!-- /Footer -->
    </body>
</html>