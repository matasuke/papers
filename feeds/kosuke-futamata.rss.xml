<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>Paper Survey - Kosuke Futamata</title><link>https://github.com/matasukef/papers/output/</link><description>NLPやCVの論文についてまとめていきます</description><lastBuildDate>Sun, 17 Jun 2018 00:00:00 +0900</lastBuildDate><item><title>Attention-based Multimodal Neural Machine Translation</title><link>https://github.com/matasukef/papers/output/attention-based-multimodal-neural-machine-translation.html</link><description></description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kosuke Futamata</dc:creator><pubDate>Sun, 17 Jun 2018 00:00:00 +0900</pubDate><guid isPermaLink="false">tag:github.com,2018-06-17:/matasukef/papers/output/attention-based-multimodal-neural-machine-translation.html</guid><category>MNMT</category><category>CV</category></item><item><title>2D/3D Pose Estimation and Action Recognition using Multitask Deep Learning</title><link>https://github.com/matasukef/papers/output/2d3d-pose-estimation-and-action-recognition-using-multitask-deep-learning.html</link><description></description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kosuke Futamata</dc:creator><pubDate>Tue, 12 Jun 2018 00:00:00 +0900</pubDate><guid isPermaLink="false">tag:github.com,2018-06-12:/matasukef/papers/output/2d3d-pose-estimation-and-action-recognition-using-multitask-deep-learning.html</guid><category>Pose Estimation</category><category>Action Recognition</category></item><item><title>Paper Survey</title><link>https://github.com/matasukef/papers/output/paper-survey.html</link><description>&lt;ul&gt;
&lt;li&gt;NLPやCVに関連する論文の概要をまとめていきます。&lt;/li&gt;
&lt;li&gt;読む予定の論文は&lt;a href="https://github.com/matasukef/papers/issues"&gt;Issue&lt;/a&gt;に上げます。&lt;/li&gt;
&lt;li&gt;進捗を&lt;a href="https://github.com/matasukef/papers/projects"&gt;Projects&lt;/a&gt;にまとめています。&lt;/li&gt;
&lt;li&gt;概要は&lt;a href="https://github.com/matasukef/papers/blob/master/Format.md"&gt;Format.md&lt;/a&gt;に基づいて作成します。&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;Format&lt;/h1&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;Title&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="err"&gt;論文タイトル&lt;/span&gt;
&lt;span class="n"&gt;Date&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;YYYY&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;MM&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;DD&lt;/span&gt;
&lt;span class="n"&gt;Category&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="n"&gt;CV&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;NLP&lt;/span&gt;
&lt;span class="n"&gt;Tags&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;ACL2018&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;WMT&lt;/span&gt;
&lt;span class="n"&gt;Author&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Kosuke&lt;/span&gt; &lt;span class="n"&gt;Futamata&lt;/span&gt;
&lt;span class="n"&gt;Summary&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;hogehoge&lt;/span&gt;

&lt;span class="err"&gt;##&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="err"&gt;どんなもの？&lt;/span&gt;

&lt;span class="err"&gt;##&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="err"&gt;先行研究と比べてどこがすごいの？&lt;/span&gt;

&lt;span class="err"&gt;##&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="err"&gt;技術や手法の&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;キモ&amp;quot;&lt;/span&gt;&lt;span class="err"&gt;はどこにある？&lt;/span&gt;

&lt;span class="err"&gt;##&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="err"&gt;どうやって有効だと検証した？&lt;/span&gt;

&lt;span class="err"&gt;##&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="err"&gt;議論はあるか？&lt;/span&gt;

&lt;span class="err"&gt;##&lt;/span&gt; &lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="err"&gt;次に読むべき論文はあるか？&lt;/span&gt;

&lt;span class="err"&gt;###&lt;/span&gt; &lt;span class="err"&gt;論文情報・リンク&lt;/span&gt;

&lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="err"&gt;著者，&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;タイトル，&amp;quot;&lt;/span&gt; &lt;span class="err"&gt;ジャーナル名，&lt;/span&gt;&lt;span class="n"&gt;voluem&lt;/span&gt;&lt;span class="err"&gt;，&lt;/span&gt;&lt;span class="n"&gt;no …&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kosuke Futamata</dc:creator><pubDate>Mon, 11 Jun 2018 00:00:00 +0900</pubDate><guid isPermaLink="false">tag:github.com,2018-06-11:/matasukef/papers/output/paper-survey.html</guid></item><item><title>Show, Attend and Tell: Neural Image Caption Generation with Visual Attention</title><link>https://github.com/matasukef/papers/output/show-attend-and-tell-neural-image-caption-generation-with-visual-attention.html</link><description></description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kosuke Futamata</dc:creator><pubDate>Mon, 11 Jun 2018 00:00:00 +0900</pubDate><guid isPermaLink="false">tag:github.com,2018-06-11:/matasukef/papers/output/show-attend-and-tell-neural-image-caption-generation-with-visual-attention.html</guid><category>IDG</category><category>Attention</category></item><item><title>Video Question Answering via Hierarchical Spatio-Temporal Attention Networks</title><link>https://github.com/matasukef/papers/output/video-question-answering-via-hierarchical-spatio-temporal-attention-networks.html</link><description></description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Kosuke Futamata</dc:creator><pubDate>Tue, 15 May 2018 00:00:00 +0900</pubDate><guid isPermaLink="false">tag:github.com,2018-05-15:/matasukef/papers/output/video-question-answering-via-hierarchical-spatio-temporal-attention-networks.html</guid><category>VQA</category><category>JICAI-17</category></item></channel></rss>